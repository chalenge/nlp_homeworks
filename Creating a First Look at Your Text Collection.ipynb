{
 "metadata": {
  "name": "",
  "signature": "sha256:d185218d0d81306999f856d212578e3953bc840ed3ecec2fc73e625965a13d45"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Goal** In this assignment, you'll make a first pass look at your newly adopted text collection similar to the Wolfram Alpha's view.\n",
      "\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Title, author, and other metadata**.  First, print out some summary information that gives the background explaining what this collection is and where it comes from:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print '%-16s' % 'Title:', \"Napoleon's Letters to Josephine\"\n",
      "print '%-16s' % 'Author:',  \"Henry Foljambe Hall\"\n",
      "print '%-16s' % 'Publisher:',  \"Ballantyne Press\"\n",
      "print '%-16s' % 'Released By:',  \"Project Gutenberg\"\n",
      "print '%-16s' % 'Release Date:', \"September 21, 2011\"\n",
      "print '%-16s' % 'Language:',  \"English\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Title:           Napoleon's Letters to Josephine\n",
        "Author:          Henry Foljambe Hall\n",
        "Publisher:       Ballantyne Press\n",
        "Released By:     Project Gutenberg\n",
        "Release Date:    September 21, 2011\n",
        "Language:        English\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import nltk\n",
      "import re\n",
      "import os\n",
      "import string\n",
      "\n",
      "from __future__ import division\n",
      "\n",
      "#Create a text tokenizer\n",
      "sent_tokenizer=nltk.data.load('tokenizers/punkt/english.pickle')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**First, load in the file or files below.**  First, take a look at your text.  An easy way to get started is to first read it in, and then run it through the sentence tokenizer to divide it up, even if this division is not fully accurate.  You may have to do a bit of work to figure out which will be the \"opening phrase\" that Wolfram Alpha shows.  Below, write the code to read in the text and split it into sentences, and then print out the **opening phrase**."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "file_path =\"Napoleon_Letters_to_Josephine.txt\"\n",
      "with open(file_path, 'r') as book:\n",
      "    text = book.read()\n",
      "\n",
      "#Split the text into sentences\n",
      "text_sentences = sent_tokenizer.tokenize(text.strip())\n",
      "\n",
      "#print out a couple of sentences\n",
      "text_sentences[:10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "['NAPOLEON\\'S LETTERS TO JOSEPHINE\\n\\n  \"When all the lesser tumults, and lesser men of our age, shall\\n  have passed away into the darkness of oblivion, history will\\n  still inscribe one mighty era with the majestic name of\\n  Napoleon.',\n",
        " '\"--LOCKHART (in Lang\\'s \"Life and Letters of J. G.\\n  Lockhart,\" 1897, vol.',\n",
        " 'i.',\n",
        " '170).',\n",
        " \"NAPOLEON'S LETTERS\\n  TO JOSEPHINE\\n\\n  1796-1812\\n\\n  FOR THE FIRST TIME COLLECTED AND\\n  TRANSLATED, WITH NOTES SOCIAL,\\n  HISTORICAL, AND CHRONOLOGICAL,\\n  FROM CONTEMPORARY SOURCES\\n\\n  BY\\n\\n  HENRY FOLJAMBE HALL\\n\\n  F.R.HIST.S.\",\n",
        " '1901\\n\\n  LONDON: J. M. DENT & CO.\\n\\n  NEW YORK: E. P. DUTTON & CO.',\n",
        " 'Printed by BALLANTYNE, HANSON & CO.\\n\\nAt the Ballantyne Press\\n\\n\\n\\n\\nPREFACE\\n\\n\\nI have no apology to offer for the subject of this book, in view of\\nLord Rosebery\\'s testimony that, until recently, we knew nothing about\\nNapoleon, and even now \"prefer to drink at any other source than the\\noriginal.',\n",
        " '\"\\n\\n\"Study of Napoleon\\'s utterances, apart from any attempt to discover\\nthe secret of his prodigious exploits, cannot be considered as lost\\ntime.',\n",
        " '\" It is then absolutely necessary that we should, in the words of\\nan eminent but unsympathetic divine, know something of the \"domestic\\nside of the monster,\" first hand from his own correspondence,\\nconfirmed or corrected by contemporaries.',\n",
        " 'There is no master mind that\\nwe can less afford to be ignorant of.']"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#print out the opening phrase.\n",
      "print text_sentences[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "NAPOLEON'S LETTERS TO JOSEPHINE\n",
        "\n",
        "  \"When all the lesser tumults, and lesser men of our age, shall\n",
        "  have passed away into the darkness of oblivion, history will\n",
        "  still inscribe one mighty era with the majestic name of\n",
        "  Napoleon.\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Next, tokenize.**  Look at the several dozen sentences to see what kind of tokenization issues you'll have.  Write a regular expression tokenizer, using the nltk.regexp_tokenize() as seen in class, to do a nice job of breaking your text up into words.  You may need to make changes to the regex pattern that is given in the book to make it work well for your text collection. \n",
      "\n",
      "*Note that this is the key part of the assignment.  How you break up the words will have effects down the line for how you can manipulate your text collection.  You may want to refine this code later.*"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pattern = r'''(?x)\n",
      "([A-Z]\\.)\\s([A-Z]\\.)\n",
      "|([A-Z]\\.)+\n",
      "|\\w+([-']\\w+)*\n",
      "|\\$?\\d+(\\.\\d+)?%?\n",
      "|[.,?;]+\n",
      "'''\n",
      "\n",
      "#Tokenize the text using the regex pattern\n",
      "words_list = nltk.regexp_tokenize(text,pattern)\n",
      "\n",
      "# Remove all punctuation from initial list of tokens\n",
      "words = [word for word in words_list if word not in string.punctuation]\n",
      "\n",
      "#Show sample token list\n",
      "words[:20]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "[\"NAPOLEON'S\",\n",
        " 'LETTERS',\n",
        " 'TO',\n",
        " 'JOSEPHINE',\n",
        " 'When',\n",
        " 'all',\n",
        " 'the',\n",
        " 'lesser',\n",
        " 'tumults',\n",
        " 'and',\n",
        " 'lesser',\n",
        " 'men',\n",
        " 'of',\n",
        " 'our',\n",
        " 'age',\n",
        " 'shall',\n",
        " 'have',\n",
        " 'passed',\n",
        " 'away',\n",
        " 'into']"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Compute word counts.** Now compute your frequency distribution using a FreqDist over the words. Let's not do lowercasing or stemming yet.  You can run this over the whole collection together, or sentence by sentence. Write the code for computing the FreqDist below."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Create a frequency distribution\n",
      "freqdist = nltk.FreqDist(words)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Creating a table.**\n",
      "Python provides an easy way to line columns up in a table.  You can specify a width for a string such as %6s, producing a string that is padded to width 6. It is right-justified by default, but a minus sign in front of it switches it to left-justified, so -3d% means left justify an integer with width 3.  *AND* if you don't know the width in advance, you can make it a variable by using an asterisk rather than a number before the '\\*s%' or the '-\\*d%'.  Check out this example (this is just fyi):"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print '%-16s' % 'Info type', '%-16s' % 'Value'\n",
      "print '%-16s' % 'number of words', '%-16d' % 100000"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Info type        Value           \n",
        "number of words  100000          \n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Word Properties Table** Next there is a table of word properties, which you should compute (skip unique word stems, since we will do stemming in class on Wed).  Make a table that prints out:\n",
      "1. number of words\n",
      "2. number of unique words\n",
      "3. average word length\n",
      "4. longest word\n",
      "\n",
      "You can make your table look prettier than the example I showed above if you like!\n",
      "\n",
      "You can decide for yourself if you want to eliminate punctuation and function words (stop words) or not.  It's your collection!  \n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print '%-25s' % 'number of words', '%-16d' % len(words)\n",
      "print '%-25s' % 'number of unique words', '%-16d' % len(set(words))\n",
      "print '%-25s' % 'average word length', '%-16.2f' %  ((sum(len(word) for word in words)) / (len(words)))\n",
      "print '%-25s' % 'longest word', '%-16s' % max(words, key=len)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "number of words           95673           \n",
        "number of unique words    11464           \n",
        "average word length       4.52            \n",
        "longest word              Charlotte-Auguste-Mathilde\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Most Frequent Words List.** Next is the most frequent words list.  This table shows the percent of the total as well as the most frequent words, so compute this number as well.  "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 'Top Ten Most Frequent Words'\n",
      "\n",
      "#Calculate the total number of words in corpus\n",
      "total_words = len(words)\n",
      "\n",
      "# Create a list of the top frequent words and calculate the percentage of total\n",
      "list([(word[0], round(((word[1]/total_words)* 100),2))  for word in freqdist.items()[:10]])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Top Ten Most Frequent Words\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 8,
       "text": [
        "[('the', 4.47),\n",
        " ('of', 3.45),\n",
        " ('to', 2.61),\n",
        " ('and', 2.45),\n",
        " ('I', 1.68),\n",
        " ('a', 1.29),\n",
        " ('in', 1.23),\n",
        " ('you', 1.17),\n",
        " ('is', 1.03),\n",
        " ('that', 0.99)]"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Most Frequent Capitalized Words List** We haven't lower-cased the text so you should be able to compute this. Don't worry about whether capitalization comes from proper nouns, start of sentences, or elsewhere. You need to make a different FreqDist to do this one.  Write the code here for the new FreqDist and the List itself.  Show the list here."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Create a list of capitalized words\n",
      "capital_words = list([word for word in words if word[0].isupper() ])\n",
      "\n",
      "#Create new frequency distribution\n",
      "cap_freqdist = nltk.FreqDist(capital_words)\n",
      "\n",
      "# Create new list of the top frequent words\n",
      "list([(word[0], round(((word[1]/total_words)* 100),2))  for word in cap_freqdist.items()[:10]])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 10,
       "text": [
        "[('I', 1.68),\n",
        " ('No', 0.65),\n",
        " ('The', 0.51),\n",
        " ('Napoleon', 0.49),\n",
        " ('TO', 0.27),\n",
        " ('THE', 0.25),\n",
        " ('AT', 0.24),\n",
        " ('NAPOLEON', 0.23),\n",
        " ('Josephine', 0.22),\n",
        " ('EMPRESS', 0.21)]"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Sentence Properties Table** This summarizes number of sentences and average sentence length in words and characters (you decide if you want to include stopwords/punctuation or not).  Print those out in a table here."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print '%-25s' % 'number of sentences', '%-10d' % len(text_sentences)\n",
      "print '%-25s' % 'average sentence length', '%-5.2f' % (len(text)/ len(text_sentences)), 'characters'\n",
      "print '%-25s' % ' ', '%-5.2f' % (total_words / len(text_sentences)), 'words'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "number of sentences       6842      \n",
        "average sentence length   84.90 characters\n",
        "                          13.98 words\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}